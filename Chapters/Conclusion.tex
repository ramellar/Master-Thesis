\section{Conclusion} \label{section: conclusion}

This thesis introduces the usage of SPANet, an attention-based neural network, for the HH $\to$ 4b analysis. Section \ref{section: improving} presents the results of using SPANet to find the best pairing between the reconstructed jets and the generator-level quarks and Section \ref{section: s/b classification} reports the results of using SPANet as a signal/background classifier.

\vspace{0.2 cm}

Regarding the pairing efficiency, it was converged upon the model that showed the highest pairing efficiency, the smallest background sculpting, and the smallest training variability. To determine this model, first, the optimal number of jets to be used in the SPANET training was assessed. Then, different SPANet hyperparameters and input variables were tested to find the model with the highest pairing efficiency. After finding the best two performing models, the background mass sculpting was verified and one of the two was selected. Nevertheless, due to the instability of this training with respect to the validation accuracy, the SPANet architecture had to be further modified until the hyperparameters resulted in a stable model. Moreover, different trainings were tested using samples with different values of $\kl$ to verify the pairing efficiency as a function of \kl. It was concluded that training the model with samples containing $\kl$ samples improved the pairing efficiency as a function of \kl and $m_{HH}$. Adding \kl explicitly as a global input did not improve the performance, therefore it was decided to not include it. Finally, the impact of different kinematic selections in the analysis was tested, i.e. using Tight or Loose cuts (Section \ref{section: HH4b}) in the training samples. It was shown that using Tight cuts for the training led to a higher pairing efficiency and less background mass sculpting. Thus, in conclusion, the SPANet model that was chosen is the SPANet - \kl - Tight selection model that uses:
\begin{itemize}
    \item \pt regressed, $\eta$, $\phi$ and b-tag of the 5 jets considered for the pairing as sequential inputs
    \item No explicit \kl input as a global variable
    \item Stable model hyperparameters (shown in Table \ref{table: stable model})
\end{itemize}
\noindent Not only this model has the best pairing efficiency among all the ones tested, but it also outperforms the pairing efficiency of the $D_{HH}$-method used in the Run 2 analysis. A 4-8\% absolute improvement (difference between the $D_{HH}$-method and SPANet performance) with respect to
the $D_{HH}$-method is observed, as well as a 5-14\% relative improvement (ratio between the $D_{HH}$-method and SPANet performance). For the total pairing efficiency as a function of the di-Higgs mass $m_{HH}$, the $D_{HH}$ method is outperformed from $m_{HH}=350$ GeV (Figure \ref{fig: mhh kl input or no input}). As a function of \kl, the $D_{HH}$ method is outperformed by 0.5\% up to \kl=2 and by 0.2\% until \kl=5 (Figure \ref{fig: loose vd tight}).

\vspace{0.2 cm}

When using SPANet as a S/B classifier, signal and background samples were used for the training. Therefore, the loss function needs to be modified and to do so, event and class weights were introduced in the computation. They allow to properly account for MC production effects and the difference in the number of signal and background events and thus avoid imbalance classification issues. Ideally, the background sample for the training would be 4b-morphed data (Section \ref{section: HH4b}). Nevertheless, as it is not possible to use it at the moment, different training configurations were tested using 2b-data, 4b-data, and 4b-QCD background samples (Section \ref{section: HH4b}) in order to infer the results for 4b-data using Eq.(\ref{eq: extrapolation}). For each background configuration, different inputs were tested: either the so-called "DNN" and "Probability Difference" (PD) variables, defined in Section \ref{section: s/b classification}, or uniquely DNN variables.  To assess the performance of the trainings, the ROC curves and the AUC values were compared. The variability of the different trainings was assessed as well, and a large variability was observed for the configuration using the 4b-QCD sample. This led to variability for the inferred 4b-data results, and the results from the DNN used for Run 3 data were then compared within this observed variability. Finally, to have a better comparison to the DNN used for the Run 3 analysis, it was decided to train and evaluate the SPANet models on samples in SR. It was concluded that the DNN for Run 3 is outperformed by the novel SPANet training using the DNN and the PD variables up to 85\% signal efficiency. After 85\% signal efficiency, the probability distribution given by SPANet is dominated by the background (Figure \ref{fig: Assigned prob 4b QCD SR}), and the samples evaluated in the SR used have very few statistics. Thus oversampling of the 4b-QCD-SR sample is proposed to compare the performance of the inferred 4b-data ROC curve to the ROC curve of the DNN for Run 3. Finally, as a next step, to further test the performance of SPANet for the classification, it is proposed to train the model using 4b-morphed data as in the standard background estimation strategy employed in the Run 2 and Run 3 analyses. 