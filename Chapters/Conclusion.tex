\section{Conclusion}

This thesis introduces the usage of SPANet, an attention-based neural network, for the HH $\to$ 4b analysis. Section \ref{section: improving} presents the results of using SPANet to find the best pairing between the reconstructed jets and the generator-level quarks and Section \ref{section: s/b classification} reports the results of using SPANet as a signal/background classifier.

\vspace{0.2 cm}

Regarding the pairing efficiency, we converged on the model that showed the highest pairing efficiency, the least background sculpting, and the smallest variability. To determine this model, first, the jet multiplicity for the training was assessed. Then, different SPANet hyperparameters and input variables were tested to find the model with the highest pairing efficiency. After finding the best two performing models, the background mass sculpting was verified and one of the two was selected. Nevertheless, due to the instability of this training with respect to the validation accuracy, the SPANet architecture had to be further modified until the hyperparameters gave rise to a more stable model. Moreover, different trainings were tested using samples with different values of $\kl$ to verify the pairing efficiency as a function of \kl. It was concluded that training the model with samples containing $\kl$ samples improved the pairing efficiency as a function of \kl and $m_{HH}$. Adding \kl explicitly as a global input did not improve the performance, therefore it was decided to not include it. Finally, the impact of different kinematic selections in the analysis was tested, i.e. using Tight or Loose cuts (Section \ref{section: HH4b}) in the training samples. It was shown that using Tight cuts for the training led to a higher pairing efficiency and less background mass sculpting. Thus, in conclusion, the SPANet model that we converged on is the SPANet - \kl - Tight selection model that uses:
\begin{itemize}
    \item \pt regressed, $\eta$, $\phi$ and b-tag of the 5 jets considered for the pairing as sequential inputs
    \item No explicit \kl input as a global variable
    \item Stable model hyperparameters (shown in Table \ref{table: stable model})
\end{itemize}
\noindent Not only this model has the best pairing efficiency among all the ones tested, but it also outperforms the pairing efficiency of the $D_{HH}$-method used in the Run 2 analysis.

\vspace{0.2 cm}

When using SPANet as a S/B classifier, signal and background samples were used for the training. Therefore, the loss function needs to be modified and to do so, event and class weights were introduced in the computation. These allow to properly account for MC production effects and the difference in the number of signal and background events and thus avoid imbalance classification problems. Ideally, the background sample for the training would be 4b-morphed data (Section \ref{section: HH4b}). Nevertheless, as it is not possible to use it at the moment, different training configurations were tested using 2b-data, 4b-data, and 4b-QCD background samples (Section \ref{section: HH4b}) in order to infer the results for 4b-data using Eq.(\ref{eq: extrapolation}). For each background configuration, different inputs were tested: either the so-called "DNN" and "Probability Difference" (PD) variables, defined in Section \ref{section: s/b classification}, or uniquely DNN variables.  To assess the performance of the trainings, the ROC curves and the AUC values were compared. The variability of the different trainings was assessed as well, and a large variability was observed for the configuration using the 4b-QCD sample. This leads to variability for the inferred 4b-data results, and the results from the DNN used for Run 3 data are then compared within this observed variability. Finally, to have a better comparison to the DNN used for the Run 3 analysis, it was decided to train and evaluate the SPANet models on SR samples. It was concluded that the DNN for Run 3 is outperformed by the novel SPANet training using the DNN and the PD variables up to 85\% signal efficiency. After this 85\% signal efficiency, the probability distribution given by SPANet is dominated by the background (Figure \ref{fig: Assigned prob 4b QCD SR}), and the SR samples used have very few statistics. Thus the oversampling of the 4b-QCD-SR sample is proposed to compare the performance of the inferred 4b-data ROC curve to the ROC curve of the DNN for Run 3. Finally, as a next step, to further test the performance of SPANet for the classification, it is proposed to train the model using 4b-morphed data. 